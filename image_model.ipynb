{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/donya/miniconda3/envs/quera/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-14 20:10:37.295599: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-14 20:10:37.430795: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-14 20:10:37.434735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.2/lib64\n",
      "2024-07-14 20:10:37.434754: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "import traceback\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import UnidentifiedImageError\n",
    "import numpy as np\n",
    "from transformers import AutoImageProcessor, ResNetModel\n",
    "from datasets import Dataset, DatasetDict\n",
    "import ast\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading images for Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login('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')\n",
    "x=load_dataset('OmidAghili/Image_Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing some images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2223\n",
    "image = x['train'][n]['image']\n",
    "label = x['train'][n]['label']\n",
    "print(x['train'].features['label'].names[label])\n",
    "print(image.size)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = Counter(x['train']['label'])\n",
    "label_counts_series = pd.Series(label_counts)\n",
    "label_counts_series.plot(kind='bar', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing invalid images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BadImages = set()\n",
    "\n",
    "for i in range(len(x['train'])):\n",
    "    try:\n",
    "        x['train'][i]['image']\n",
    "    except:\n",
    "        print(i)\n",
    "        BadImages.add(i)\n",
    "\n",
    "x['train'] = x['train'].select(\n",
    "    (\n",
    "        i for i in range(len(x['train']))\n",
    "        if i not in BadImages\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning noisy labels**\n",
    "\n",
    "We used the code below to get \"accuracy_score.csv\" on kaggle because of GPU limitation on our local machine.\n",
    "\n",
    "![Sample Image](clean.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"accuracy_scores.csv\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongIndexList = []\n",
    "\n",
    "for i in range(len(x['train'])):\n",
    "    label = x['train'][i]['label']\n",
    "    dataset_label = x['train'].features['label'].names[label]\n",
    "    predicted_label =  ast.literal_eval(scores['0'][i])['label']\n",
    "    if dataset_label != predicted_label:\n",
    "        print(\"predicted wrong\", i)\n",
    "        wrongIndexList.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrongIndexList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets check some of the images predicted having wrong labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = wrongIndexList[2889]\n",
    "image = x['train'][n]['image']\n",
    "label = x['train'][n]['label']\n",
    "print(\"dataset \", x['train'].features['label'].names[label])\n",
    "print(\"predicted \", ast.literal_eval(scores['0'][n])['label'])\n",
    "print(image.size)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we remove noisy data and then check the distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['train'] = x['train'].select(\n",
    "    (\n",
    "        i for i in range(len(x['train']))\n",
    "        if i not in wrongIndexList\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x['train'])\n",
    "# x.push_to_hub('OmidAghili/food22Cleaned')\n",
    "\n",
    "with open('clean_dataset.pickle', 'wb') as f:\n",
    "    pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_dataset.pickle', 'rb') as f:\n",
    "    loaded_dataset = pickle.load(f)\n",
    "\n",
    "loaded_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = Counter(x['train']['label'])\n",
    "label_counts_series = pd.Series(label_counts)\n",
    "label_counts_series.plot(kind='bar', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "n = len(x['train'])\n",
    "batch_size = 32\n",
    "data = []\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    for i in range(0, n, batch_size):\n",
    "        print(i)\n",
    "        batch = x['train'][i:i+batch_size]['image']\n",
    "        processed = image_processor(batch, return_tensors='tf')\n",
    "        reshaped_images = tf.transpose(processed['pixel_values'], perm=[0, 2, 3, 1])\n",
    "        batch_labels = x['train'][i:i+batch_size]['label']\n",
    "        batch_dataset = tf.data.Dataset.from_tensor_slices((reshaped_images, batch_labels))\n",
    "        data.append(batch_dataset)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting into train and validation + one hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = data[0].concatenate(data[1])\n",
    "for dataset in data[2:]:\n",
    "    full_dataset = full_dataset.concatenate(dataset)\n",
    "\n",
    "dataset_size = full_dataset.cardinality().numpy()\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "full_dataset = full_dataset.shuffle(buffer_size=dataset_size, reshuffle_each_iteration=False)\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "val_dataset = full_dataset.skip(train_size)\n",
    "\n",
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=22)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(one_hot_encode)\n",
    "val_dataset = val_dataset.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data augmentation (if needed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "number_of_classes = 22\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(512, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.4)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(128, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.4)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(16, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.4)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "output = Dense(number_of_classes, activation='softmax')(X)\n",
    "\n",
    "model1 = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "n_epoch = 50\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    "    workers=4\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
